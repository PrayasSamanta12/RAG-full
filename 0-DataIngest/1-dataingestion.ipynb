{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f38344ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63a9b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter,CharacterTextSplitter,TokenTextSplitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d02f0",
   "metadata": {},
   "source": [
    "## Understanding the Document Structure in LangChian\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f9fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document content:This is a sample document used to demonstrate the Document structure in LangChain. It contains text data that can be processed and manipulated using various tools and libraries within the LangChain ecosystem.\n"
     ]
    }
   ],
   "source": [
    "doc=Document(\n",
    "    page_content=\"This is a sample document used to demonstrate the Document structure in LangChain. It contains text data that can be processed and manipulated using various tools and libraries within the LangChain ecosystem.\",\n",
    "    metadata={\"source\": \"sample_document.txt\", \"author\": \"OpenAI\"}\n",
    ")\n",
    "# meta data is  important part of Document Structure in the Langchain because it helps to understand where the chunk came from extra meta\n",
    "# data it helps RAG to distinguish different chunks\n",
    "print(f\"Document content:{doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b2d8a4",
   "metadata": {},
   "source": [
    "### Reading a simple text file (both creation from code as well as reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c96b36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"data/textfiles\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d5d7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text files created in data/textfiles/ directory.\n"
     ]
    }
   ],
   "source": [
    "sample_text={\n",
    "    \"data/textfiles/doc1.txt\":\"\"\"Modern organizations increasingly rely on data-driven decision-making to improve efficiency and accuracy. As businesses scale, they accumulate vast amounts of operational, transactional, and behavioral data. Turning this raw information into actionable insights requires a combination of strong data engineering pipelines, analytical models, and visualization tools. By building systems that automate data collection and transform it into structured formats, companies can better understand trends, detect anomalies, and respond proactively to changing conditions.\"\"\",\n",
    "    \"data/textfiles/doc2.txt\":\"\"\"In recent years, the field of artificial intelligence (AI) has seen significant advancements, particularly in machine learning and deep learning techniques. These technologies enable computers to learn from data and make predictions or decisions without being explicitly programmed. AI applications span various industries, including healthcare, finance, and transportation, where they enhance capabilities such as image recognition, natural language processing, and autonomous driving. As AI continues to evolve, ethical considerations around bias, privacy, and transparency remain critical topics of discussion.\"\"\",\n",
    "}\n",
    "for filepath, text in sample_text.items():\n",
    "    with open (filepath,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "print(\"Sample text files created in data/textfiles/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d965f",
   "metadata": {},
   "source": [
    "### Reading file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8292c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[Document(metadata={'source': 'data/textfiles/doc1.txt'}, page_content='Modern organizations increasingly rely on data-driven decision-making to improve efficiency and accuracy. As businesses scale, they accumulate vast amounts of operational, transactional, and behavioral data. Turning this raw information into actionable insights requires a combination of strong data engineering pipelines, analytical models, and visualization tools. By building systems that automate data collection and transform it into structured formats, companies can better understand trends, detect anomalies, and respond proactively to changing conditions.')]\n",
      "Loaded 1 document(s).\n",
      "Document content: Modern organizations increasingly rely on data-driven decision-making to improve efficiency and accuracy. As businesses scale, they accumulate vast amounts of operational, transactional, and behavioral data. Turning this raw information into actionable insights requires a combination of strong data engineering pipelines, analytical models, and visualization tools. By building systems that automate data collection and transform it into structured formats, companies can better understand trends, detect anomalies, and respond proactively to changing conditions.\n",
      "Loaded 1 document(s).\n",
      "Document content: In recent years, the field of artificial intelligence (AI) has seen significant advancements, particularly in machine learning and deep learning techniques. These technologies enable computers to learn from data and make predictions or decisions without being explicitly programmed. AI applications span various industries, including healthcare, finance, and transportation, where they enhance capabilities such as image recognition, natural language processing, and autonomous driving. As AI continues to evolve, ethical considerations around bias, privacy, and transparency remain critical topics of discussion.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader1=TextLoader(\"data/textfiles/doc1.txt\",encoding=\"utf-8\")\n",
    "loader2=TextLoader(\"data/textfiles/doc2.txt\",encoding=\"utf-8\")\n",
    "documents1=loader1.load() # list of Document objects\n",
    "print(type(documents1))\n",
    "print(documents1)\n",
    "print(f\"Loaded {len(documents1)} document(s).\")\n",
    "for doc in documents1:\n",
    "    print(f\"Document content: {doc.page_content}\")\n",
    "documents2=loader2.load() # list of Document objects\n",
    "print(f\"Loaded {len(documents2)} document(s).\")\n",
    "for doc in documents2:\n",
    "    print(f\"Document content: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3a9c2b",
   "metadata": {},
   "source": [
    "### Reading raw data from the directory using DirectoryLoader(Multiple files read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92ad55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 document(s) from directory.\n",
      "Document content: Modern organizations increasingly rely on data-driven decision-making to improve efficiency and accuracy. As businesses scale, they accumulate vast amounts of operational, transactional, and behavioral data. Turning this raw information into actionable insights requires a combination of strong data engineering pipelines, analytical models, and visualization tools. By building systems that automate data collection and transform it into structured formats, companies can better understand trends, detect anomalies, and respond proactively to changing conditions.\n",
      "Document content: In recent years, the field of artificial intelligence (AI) has seen significant advancements, particularly in machine learning and deep learning techniques. These technologies enable computers to learn from data and make predictions or decisions without being explicitly programmed. AI applications span various industries, including healthcare, finance, and transportation, where they enhance capabilities such as image recognition, natural language processing, and autonomous driving. As AI continues to evolve, ethical considerations around bias, privacy, and transparency remain critical topics of discussion.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "loader=DirectoryLoader(\"data/textfiles\",glob=\"**/*.txt\",loader_cls=TextLoader,loader_kwargs={\"encoding\":\"utf-8\"})\n",
    "# glob is basically file pattern matching\n",
    "# if only text files present in the directory then glob can be \"*.txt\" and loader_cls is TextLoader\n",
    "# if multiple file types are present in the directory then glob can be \"**/*.*\" and loader_cls can be UnstructuredFileLoader\n",
    "documents=loader.load() # list of Document objects\n",
    "print(f\"Loaded {len(documents)} document(s) from directory.\")\n",
    "for doc in documents:\n",
    "    print(f\"Document content: {doc.page_content}\")\n",
    "\n",
    "# For DirectoryLoader the directory must consist of same type of files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0718d1e8",
   "metadata": {},
   "source": [
    "### Chunking Techniques\n",
    "## Different splitting techniques which is used to split into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c769dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modern organizations increasingly rely on data-driven decision-making to improve efficiency and accuracy. As businesses scale, they accumulate vast amounts of operational, transactional, and behavioral data. Turning this raw information into actionable insights requires a combination of strong data engineering pipelines, analytical models, and visualization tools. By building systems that automate data collection and transform it into structured formats, companies can better understand trends, detect anomalies, and respond proactively to changing conditions.\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a78755e",
   "metadata": {},
   "source": [
    "### Recursive Character Text Splitter\n",
    "✅ MOST RECOMMENDED splitter\n",
    "✅ Smartly splits text using a hierarchy of separators\n",
    "✅ Falls back gradually until chunk size is satisfied\n",
    "\n",
    "✅ How it works (conceptually):\n",
    "\n",
    "It tries to split in this order:\n",
    "\n",
    "[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "\n",
    "\n",
    "Meaning:\n",
    "\n",
    "Try splitting by paragraphs\n",
    "\n",
    "If too long → split by lines\n",
    "\n",
    "If too long → split by sentences\n",
    "\n",
    "If too long → split by spaces\n",
    "\n",
    "If still too long → force split by character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a378b510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- RecursiveCharacterTextSplitter -----\n",
      "<class 'list'>\n",
      "Total chunks created: 9\n",
      "--- Chunk 1 ---\n",
      "Modern organizations increasingly rely on data-driven decision-making to improve efficiency and accuracy\n",
      "\n",
      "\n",
      "--- Chunk 2 ---\n",
      ". As businesses scale, they accumulate vast amounts of operational, transactional, and behavioral data\n",
      "\n",
      "\n",
      "--- Chunk 3 ---\n",
      ". Turning this raw information into actionable insights requires a combination of strong data engineering pipelines, analytical models, and visualization tools\n",
      "\n",
      "\n",
      "--- Chunk 4 ---\n",
      ". By building systems that automate data collection and transform it into structured formats, companies can better understand trends, detect anomalies, and respond proactively to changing conditions.\n",
      "\n",
      "\n",
      "--- Chunk 5 ---\n",
      "In recent years, the field of artificial intelligence (AI) has seen significant advancements, particularly in machine learning and deep learning techniques\n",
      "\n",
      "\n",
      "--- Chunk 6 ---\n",
      ". These technologies enable computers to learn from data and make predictions or decisions without being explicitly programmed\n",
      "\n",
      "\n",
      "--- Chunk 7 ---\n",
      ". AI applications span various industries, including healthcare, finance, and transportation, where they enhance capabilities such as image recognition, natural language processing, and autonomous\n",
      "\n",
      "\n",
      "--- Chunk 8 ---\n",
      "and autonomous driving\n",
      "\n",
      "\n",
      "--- Chunk 9 ---\n",
      ". As AI continues to evolve, ethical considerations around bias, privacy, and transparency remain critical topics of discussion.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter,CharacterTextSplitter,TokenTextSplitter\n",
    "print(\"----- RecursiveCharacterTextSplitter -----\")\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    separators=[\"\\n\\n\",\"\\n\",\".\",\" \",\"\"],\n",
    "    length_function=len\n",
    ")\n",
    "chunks=text_splitter.split_documents(documents)\n",
    "print(type(chunks))\n",
    "print(f\"Total chunks created: {len(chunks)}\")\n",
    "for i,chunk in enumerate(chunks):\n",
    "    print(f\"--- Chunk {i+1} ---\")\n",
    "    print(chunk.page_content)\n",
    "    print(\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cb47a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CharacterTextSplitter -----\n",
      "Total chunks created: 8\n",
      "--- Chunk 1 ---\n",
      "Modern organizations increasingly rely on data-driven decision-making to improve efficiency and accuracy. As businesses scale, they accumulate vast amounts of operational, transactional, and\n",
      "\n",
      "\n",
      "--- Chunk 2 ---\n",
      "transactional, and behavioral data. Turning this raw information into actionable insights requires a combination of strong data engineering pipelines, analytical models, and visualization tools. By\n",
      "\n",
      "\n",
      "--- Chunk 3 ---\n",
      "tools. By building systems that automate data collection and transform it into structured formats, companies can better understand trends, detect anomalies, and respond proactively to changing\n",
      "\n",
      "\n",
      "--- Chunk 4 ---\n",
      "to changing conditions.\n",
      "\n",
      "\n",
      "--- Chunk 5 ---\n",
      "In recent years, the field of artificial intelligence (AI) has seen significant advancements, particularly in machine learning and deep learning techniques. These technologies enable computers to\n",
      "\n",
      "\n",
      "--- Chunk 6 ---\n",
      "enable computers to learn from data and make predictions or decisions without being explicitly programmed. AI applications span various industries, including healthcare, finance, and transportation,\n",
      "\n",
      "\n",
      "--- Chunk 7 ---\n",
      "and transportation, where they enhance capabilities such as image recognition, natural language processing, and autonomous driving. As AI continues to evolve, ethical considerations around bias,\n",
      "\n",
      "\n",
      "--- Chunk 8 ---\n",
      "around bias, privacy, and transparency remain critical topics of discussion.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "print(\"----- CharacterTextSplitter -----\")\n",
    "text_splitter=CharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    separator=\" \",\n",
    "    length_function=len\n",
    ")\n",
    "chunks=text_splitter.split_documents(documents)\n",
    "print(f\"Total chunks created: {len(chunks)}\")\n",
    "for i,chunk in enumerate(chunks):\n",
    "    print(f\"--- Chunk {i+1} ---\")\n",
    "    print(chunk.page_content)\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec1c5ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- TokenTextSplitter -----\n",
      "Total chunks created: 5\n",
      "--- Chunk 1 ---\n",
      "Modern organizations increasingly rely on data-driven decision-making to improve efficiency and accuracy. As businesses scale, they accumulate vast amounts of operational, transactional, and behavioral data. Turning this raw information into actionable insights requires a combination of strong data engineering\n",
      "\n",
      "\n",
      "--- Chunk 2 ---\n",
      " actionable insights requires a combination of strong data engineering pipelines, analytical models, and visualization tools. By building systems that automate data collection and transform it into structured formats, companies can better understand trends, detect anomalies, and respond proactively to changing conditions.\n",
      "\n",
      "\n",
      "--- Chunk 3 ---\n",
      "In recent years, the field of artificial intelligence (AI) has seen significant advancements, particularly in machine learning and deep learning techniques. These technologies enable computers to learn from data and make predictions or decisions without being explicitly programmed. AI applications span various industries,\n",
      "\n",
      "\n",
      "--- Chunk 4 ---\n",
      " being explicitly programmed. AI applications span various industries, including healthcare, finance, and transportation, where they enhance capabilities such as image recognition, natural language processing, and autonomous driving. As AI continues to evolve, ethical considerations around bias, privacy, and transparency\n",
      "\n",
      "\n",
      "--- Chunk 5 ---\n",
      ", ethical considerations around bias, privacy, and transparency remain critical topics of discussion.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "print(\"----- TokenTextSplitter -----\")\n",
    "text_splitter=TokenTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    ")\n",
    "chunks=text_splitter.split_documents(documents)\n",
    "print(f\"Total chunks created: {len(chunks)}\")   \n",
    "for i,chunk in enumerate(chunks):\n",
    "    print(f\"--- Chunk {i+1} ---\")\n",
    "    print(chunk.page_content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e419b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

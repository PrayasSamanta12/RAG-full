{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d6815c",
   "metadata": {},
   "source": [
    "### How to work with Chormadb and store it in a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5f5348",
   "metadata": {},
   "source": [
    "- Here we insert docs into db\n",
    "- Uses search operation on it\n",
    "- Get the context\n",
    "- Provide that context to the LLM with scores\n",
    "- Generate the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a41006a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a0a2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PROST CODE\\Agentic AI\\RAG-full\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# langchain + chormadb\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "#for chromadb\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from typing import List\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0561680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_array = [\n",
    "    \"Python is renowned for its flexible data structures, which include lists, tuples, sets, and dictionaries. Lists are ordered collections that support dynamic resizing and a variety of methods for adding, removing, or searching elements. Tuples are similar to lists but immutable, ensuring that data remains unchanged once assigned and making them suitable for fixed data groupings. Dictionaries use key-value pairs allowing fast access, manipulation, and association of data by unique keys. Sets are collections of unordered, unique elements, great for removing duplicates and performing mathematical operations like unions and intersections. These data structures form the backbone for efficient algorithm development, making Python popular for data engineering, scientific computing, and rapid prototyping in diverse software projects.\"\n",
    "    ,\n",
    "    \"Docker containers have revolutionized application deployment by encapsulating all dependencies within lightweight, portable units. The container lifecycle runs through image creation, build, run, and destruction, allowing consistency across environments from a developer’s laptop to cloud production servers. Networking and persistent storage are handled through Docker’s bridge networks and mounted volumes, often configured in a YAML file for orchestration. Security features, resource limits, and automated health checks help maintain uptime and isolation. Command-line tools and APIs provide granular control, while platforms like Kubernetes extend management to large-scale clusters. Docker’s architecture enables microservices, CI/CD pipelines, and efficient scaling for modern software infrastructure.\"\n",
    "    ,\n",
    "    \"Vector databases have emerged as critical infrastructure for AI-driven applications by enabling the fast, approximate search of high-dimensional embeddings. Unlike traditional relational stores, vector DBs represent data points as mathematical vectors, supporting similarity queries, KNN search, and clustering. This approach underpins semantic retrieval in RAG systems, recommendation engines, and fraud detection. Technologies such as Pinecone, Weaviate, and ChromaDB offer APIs to store, update, and query embeddings generated by models like BERT or CLIP. They optimize for speed and scalability with techniques including approximate neighbors, distributed indexing, and GPU acceleration. Advanced filtering and metadata support enable hybrid retrieval for context-aware generative AI solutions.\"\n",
    "    ,\n",
    "    \"SQL query optimization is crucial for scalable database operations. Indexing frequently searched columns is an essential strategy, but too many indexes can degrade write performance. Queries should avoid ‘SELECT *’, minimize joins to essential tables, and use WHERE clauses that leverage indexed columns. Tools like EXPLAIN PLAN visualize execution steps, guiding developers to restructure queries for efficiency. Partitioning large tables can improve access speed while reducing locking contention. Regularly updating table statistics ensures the optimizer selects the best execution path. Avoiding correlated subqueries and using batch processing techniques can reduce resource consumption. These approaches together lead to faster, more reliable database systems.\"\n",
    "    ,\n",
    "    \"In Node.js, the event loop is a key mechanism that allows non-blocking I/O operations on a single thread. Each incoming request is delegated to the system kernel, freeing the JavaScript runtime to handle other events. Async callbacks are queued and executed when the kernel signals completion, drastically improving throughput. Promises and async/await syntax further simplify asynchronous code management, reducing callback hell and enhancing maintainability. Node.js excels in microservices, web servers, and real-time applications like chat or streaming services. Its event-driven model, combined with fast V8 execution, supports horizontal scaling and resource-efficient concurrency on modest hardware, making Node.js immensely popular for backend services.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b360b42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc created\n"
     ]
    }
   ],
   "source": [
    "# Storing the samlpes in a file\n",
    "import tempfile\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(strings_array):\n",
    "    file_path = os.path.join(temp_dir, f\"doc_{i}.txt\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(\"Doc created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fcc64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Document loading\n",
    "from langchain_community.document_loaders import DirectoryLoader,TextLoader\n",
    "load = DirectoryLoader(\n",
    "    temp_dir,\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"}\n",
    ")\n",
    "\n",
    "documents=load.load()\n",
    "for i,doc in enumerate(documents):\n",
    "    print(f\"Document {i}:\\n{doc.page_content}\")\n",
    "    print(f\"Metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e640cdc",
   "metadata": {},
   "source": [
    "### Text Splitting from docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28eaa9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 15 of 5\n",
      "Content: page_content='Python is renowned for its flexible data structures, which include lists, tuples, sets, and dictionaries. Lists are ordered collections that support dynamic resizing and a variety of methods for adding, removing, or searching elements. Tuples are similar to lists but immutable, ensuring that data' metadata={'source': 'C:\\\\Users\\\\ps19j\\\\AppData\\\\Local\\\\Temp\\\\tmppjdesij8\\\\doc_0.txt'}\n",
      "Metadata: {'source': 'C:\\\\Users\\\\ps19j\\\\AppData\\\\Local\\\\Temp\\\\tmppjdesij8\\\\doc_0.txt'}\n"
     ]
    }
   ],
   "source": [
    "# Text Splitting\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    separators=[\" \"]\n",
    ")\n",
    "chunks=splitter.split_documents(documents)\n",
    "print(f\"Total chunks: {len(chunks)} of {len(documents)}\")\n",
    "print(f\"Content: {chunks[0]}\")\n",
    "print(f\"Metadata: {chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1551f490",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3856e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "embeddings=HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    ")\n",
    "embeddings.embed_query(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1181460e",
   "metadata": {},
   "source": [
    "#### Storing into ChromaDB using HuggingFace Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adfbb696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created at ./chromaDB\n",
      "Number of vectors: 20\n"
     ]
    }
   ],
   "source": [
    "# Directory of ChromaDB\n",
    "persistant_directory = \"./chromaDB\"\n",
    "\n",
    "VECTOR_STORE = Chroma(\n",
    "    persist_directory=persistant_directory,\n",
    "    embedding_function=HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    ),\n",
    "    collection_name=\"Rag_collection\"\n",
    ")\n",
    "VECTOR_STORE.add_documents(chunks)\n",
    "print(f\"Vector store created at {persistant_directory}\")\n",
    "print(f\"Number of vectors: {VECTOR_STORE._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "774c5738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'C:\\\\Users\\\\ps19j\\\\AppData\\\\Local\\\\Temp\\\\tmppjdesij8\\\\doc_4.txt'}, page_content='signals completion, drastically improving throughput. Promises and async/await syntax further simplify asynchronous code management, reducing callback hell and enhancing maintainability. Node.js excels in microservices, web servers, and real-time applications like chat or streaming services. Its'), Document(metadata={'source': 'C:\\\\Users\\\\ps19j\\\\AppData\\\\Local\\\\Temp\\\\tmppjdesij8\\\\doc_4.txt'}, page_content='In Node.js, the event loop is a key mechanism that allows non-blocking I/O operations on a single thread. Each incoming request is delegated to the system kernel, freeing the JavaScript runtime to handle other events. Async callbacks are queued and executed when the kernel signals completion, drastically improving throughput. Promises and async/await syntax further simplify asynchronous code management, reducing callback hell and enhancing maintainability. Node.js excels in microservices, web servers, and real-time applications like chat or streaming services. Its event-driven model, combined with fast V8 execution, supports horizontal scaling and resource-efficient concurrency on modest hardware, making Node.js immensely popular for backend services.'), Document(metadata={'source': 'C:\\\\Users\\\\ps19j\\\\AppData\\\\Local\\\\Temp\\\\tmppjdesij8\\\\doc_4.txt'}, page_content='services. Its event-driven model, combined with fast V8 execution, supports horizontal scaling and resource-efficient concurrency on modest hardware, making Node.js immensely popular for backend services.')]\n"
     ]
    }
   ],
   "source": [
    "query=\"How to work with Node js?\"\n",
    "similar_chunks=VECTOR_STORE.similarity_search(query, k=3)\n",
    "print(similar_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae139f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo-proj (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
